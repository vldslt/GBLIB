==================================================================================================================================================================
Приведите по 2 примера, когда лучше максимизировать Precision, а когда Recall.
==================================================================================================================================================================

Чтобы не зависеть от абсолютного количества событий для измерения качества классификаторов, придуманы различные относительные меры качества — например, чувствительность (sensitivity, полнота recall), определенность (specificity) и точность (precision): Sensitivity = TP / (TP + FN) — вероятность того, что тест скажет, что пациент болен, если пациент действительно болен; Specificity = TN / (TN + FP) — вероятность того, что тест скажет, что пациент здоров, если он здоров; Precision = TP / (TP + FP) — доля правильно отобранных больных к общему числу отобранных алгоритмом больных.
Если кредитная политика банка направлена на большую выручку, имеет смысл максимизировать Recall; если кредитная политика банка направлена на репутацию (макс. клиентов платежеспособны), имеет смысл максимизировать Precision.
Recall aka sensitivity, hit rate, or true positive rate (TPR)
Мне кажется, hit rate и TPR лучше всего отражают суть. В этой метрике мы рассматриваем только P-случаи: когда в реальных наблюдениях было "да". И считаем, какую долю из этих случаев модель предсказала правильно.Recall сам по себе довольно бесполезен. Взглядните на результаты для нашей модели: модель, которая всегда тупо говорить "да" — безусловно побеждает. Фактически, recall пропорционалент TP, если P — константа (напомню, что это просто количество ответов "да" в наших фактических данных).
Precision aka positive predictive value (PPV)
Какая часть наших предсказаний "да" действительно сбылась.Недостатки этой метрики аналогичны: она вообще никак не учитывает предсказания "нет". Из наших результатов видно, что побеждает модель, которая почти всегда говорить "нет". Она какбы снижает риск проиграть, выводя большую часть своих ответ за рамки рассмотрения.

==================================================================================================================================================================
Почему мы используем F-меру, почему, например, нельзя просто взять среднее от Precision и Recall?
==================================================================================================================================================================

Первая причина в том, что F-мера позволяет оценить в комплексе как Precision, так и Recall.
Вторая причина в том, что F-мера позволяет увеличивать/уменьшать влияние Precision и Recall
Среднее по гармонике является эквивалентом среднего арифметического для обратных величин, которые должны быть усреднены по среднему арифметическому. Точнее, с помощью гармонического среднего вы преобразуете все свои числа в "усредненную" форму (взяв обратную величину), берете их среднее арифметическое и затем преобразовываете результат обратно в исходное представление (снова взяв обратную величину).Точность и отзыв "естественно" взаимны, потому что их числитель одинаков, а знаменатели разные. Фракции более чувствительны к усреднению по среднему арифметическому, когда они имеют одинаковый знаменатель.
Для большей интуиции предположим, что мы сохраняем число истинно положительных элементов постоянным. Затем, взяв среднее гармоническое значение точности и отзыва, вы неявно берете среднее арифметическое ложных срабатываний и ложных отрицаний. Это в основном означает, что ложные срабатывания и ложные отрицания одинаково важны для вас, когда истинные положительные результаты остаются прежними. Если в алгоритме есть N больше ложных положительных элементов, но меньше N ложных отрицательных (при том же самом истинном положительном значении), F-мера остается прежней.
Чтобы объяснить, рассмотрим, например, что такое среднее значение 30 миль в час и 40 миль в час? если вы едете в течение 1 часа на каждой скорости, средняя скорость за эти 2 часа действительно равна среднему арифметическому-35 миль в час.
Однако если вы едете на одно и то же расстояние на каждой скорости-скажем, 10 миль, - то средняя скорость более 20 миль-это среднее гармоническое значение 30 и 40, около 34.3mph.
Причина в том, что для того, чтобы среднее значение было действительным, вам действительно нужно, чтобы значения были в одних и тех же масштабированных единицах. Мили в час нужно сравнивать за то же самое количество часов; чтобы сравнить за то же самое количество миль, вам нужно усреднить часы на милю, что и делает среднее гармоническое.
Точность и отзыв имеют истинные положительные значения в числителе и разные знаменатели. Чтобы усреднить их, на самом деле имеет смысл только усреднить их взаимные отношения, таким образом, гармоническое среднее.

==================================================================================================================================================================
В чём различие между зависимыми и независимыми выборками?
==================================================================================================================================================================

Когда одному случаю из выборки X соответствует один и только один случай из выборки Y и наоборот для каждого случая в двух выборках (и это основание взаимосвязи является важным для измеряемого на выборках признака), такие выборки называются зависимыми. Если такая взаимосвязь между выборками отсутствует, то эти выборки считаются независимыми

==================================================================================================================================================================
Когда применяются параметрические статистические критерии, а когда — их непараметрические аналоги?
==================================================================================================================================================================

Главное условие применения параметрических критериев – нормальность распределения анализируемых переменных. Следствием этого условия является правомерность применения таких характеристик, как среднее значение и стандартное отклонение. Отсюда и название критериев – параметрические критерии – в формулу их расчета включаются такие характеристики выборки как среднее значение и дисперсия. Для каждого параметрического критерия имеется, по крайней мере, один непараметрический аналог. 
Непараметрические методы разработаны для тех ситуаций, когда исследователь ничего не знает о параметрах исследуемой популяции (отсюда и название методов - непараметрические).Непараметрические методы позволяют обрабатывать данные "низкого качества" из выборок малого объема с переменными, про распределение которых мало что или вообще ничего не известно. Непараметрические методы наиболее приемлемы, когда объем выборок мал. Если данных много (например, n > 100), то не имеет смысла использовать непараметрические статистики. Непараметрические тесты имеют меньшую статистическую мощность (менее чувствительны), чем их параметрические конкуренты, и если важно обнаружить даже слабые отклонения, следует особенно внимательно выбирать статистику критерия.

==================================================================================================================================================================
Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?
==================================================================================================================================================================

Макро — вычисление метрики для каждого класса и получение невзвешенного среднего
Микро — расчет метрики на глобальном уровне путем подсчета итоговых истинных положительных результатов, ложноотрицательных и ложноположительных результатов (независимо от классов).
Взвешенный — вычисление метрик для каждого класса и получение взвешенного среднего по числу выборок на каждый класс.
Микро- и макро-средние (для любой метрики) будут вычислять несколько разные вещи, и, следовательно, их интерпретация будет разной. Макро-среднее вычислит метрику независимо для каждого класса, а затем возьмет среднее (следовательно, будет обрабатывать все классы одинаково), тогда как микро-среднее будет агрегировать вклады всех классов для вычисления средней метрики. В мультиклассовой классификации предпочтение отдается микро-среднему, если вы подозреваете, что может быть дисбаланс классов (т.е. у вас может быть гораздо больше примеров одного класса, чем других классов).

==================================================================================================================================================================
В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?
==================================================================================================================================================================

LightGBM использует новую технику односторонней выборки на основе градиента (GOSS) для фильтрации экземпляров данных для нахождения значения разделения,в то время как XGBoost использует предварительно отсортированный алгоритм и алгоритм на основе гистограммы для вычисления наилучшего разделения.
Алгоритм сегментации, XGBoost использует pre_sorted, а LightGBM использует гистограмму.
Стратегия роста дерева решений: XGBoost использует уровень с ограничением глубины для разделения одного и того же слоя листьев за раз. LightGBM использует поэтапный рост, чтобы каждый раз находить лист с наибольшим усилением разделения из всех текущих листьев.
CatBoost обладает гибкостью, позволяя задавать индексы категориальных столбцов, чтобы его можно было кодировать как кодирование в одно касание с использованием one_hot_max_size (используйте кодирование в одно касание для всех функций с числом различных значений, меньшим или равным данному значению параметра).Если вы ничего не передаете в аргументе cat_features, CatBoost будет обрабатывать все столбцы как числовые переменные.
Как и в CatBoost, LightGBM также может обрабатывать категориальные функции, вводя имена функций. Он не конвертируется в одноразовое кодирование и намного быстрее, чем одноразовое кодирование. LGBM использует специальный алгоритм, чтобы найти значение разделения категориальных признаков.
По сравнению с традиционным GBDT, XGBoost может автоматически использовать многопоточность ЦП, поддерживать линейные классификаторы, использовать производные второго порядка для оптимизации, добавлять обычные элементы в функцию стоимости, может автоматически обрабатывать отсутствующие значения и поддерживать параллелизм (с детализацией функций) .
В отличие от CatBoost или LGBM, XGBoost не может обрабатывать категориальные функции сам по себе, он принимает только числовые значения, подобные случайному лесу. Поэтому перед подачей категориальных данных в XGBoost необходимо выполнить различные кодировки, такие как кодирование меток, среднее кодирование или однократное кодирование.

==================================================================================================================================================================
Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?
==================================================================================================================================================================

Целью машинного обучения является моделирование модели и игнорирование шума. Каждый раз, когда алгоритм пытается соответствовать шуму в дополнение к шаблону, он переоснащается. В контролируемом параметре обычно требуется сопоставить выходные данные функции прогнозирования с метками обучения. По мере того, как вы добавляете все больше и больше переменных,вы склонны делать более точные прогнозы по данным обучения. Тем не менее, помимо этого, добавление большего количества переменных не помогает в моделировании паттерна, а только пытается соответствовать шуму. Поскольку шум является стохастическим, это плохо обобщает невидимые данные, и поэтому у вас низкая ошибка обучения и высокая ошибка теста.
На большую часть контролируемого машинного обучения можно взглянуть, используя следующую структуру: у вас есть набор обучающих точек (xi, yi) (xi, yi) (x_i, y_i), и вы хотите найти функцию fff, которая "соответствует данным хорошо ", то есть yi ≈ f (xi) yi ≈ f (xi) y_i \ ок. f (x_i) для большинства iii. Эту функцию нужно выбирать осторожно - если она слишком проста, y i ≈ f (x i) y i ≈ f (x i) y_i \ приблизительный f (x_i) может не выполняться для многих значений i i i; если он слишком сложный, он очень хорошо вписывается в данные (может быть, даже идеально), но не подходит для невидимых данных.

Вы задаете сложность выбранной функции следующим образом: выберите класс функций FF \ mathcal {F}, сложностью которого проще управлять, а затем найдите функцию f ∈ F f ∈ F f \ in \ mathcal {F}, который лучше всего подходит для данных обучения. Таким образом, проблема управления сложностью f f f была сведена к задаче управления сложностью F F \ mathcal {F}. Теперь, так как нет прямого способа найти оптимальное FF \ mathcal {F}, вы попробуйте набор классов функций F 1,…, F k F 1,…, F k \ mathcal {F} _1, \ ldots, \ mathcal {F} _k, и выберите тот, который лучше всего подходит для невидимых данных. Эти классы F 1,…, F k F 1,…, F k \ mathcal {F} _1, \ ldots, \ mathcal {F} _k параметризуются величинами, называемыми гиперпараметрами, а процесс выбора лучшего класса называется гиперпараметром оптимизация.

Давайте рассмотрим небольшой пример. Предположим, у вас есть проблема с классификацией. Вы планируете использовать деревья решений для задачи. Сложность деревьев решений определяется их глубиной. Таким образом, вы берете функциональные классы T 1,…, T k T 1,…, T k T_1, \ ldots, T_k, где T i T i T_i - это множество всех деревьев решений глубины не более i i i. Поэтому эти функциональные классы параметризованы гиперпараметром i i i - только эта величина отличает один класс от другого. Вы пробуете различные значения i i i, подбираете самое лучшее дерево глубины, самое большее i i i, для данных обучения и выбираете одно с минимальной ошибкой для невидимых данных. Таким образом, нахождение (почти) оптимального значения i i i является процессом оптимизации гиперпараметра.

Теперь вместо того, чтобы явно фиксировать глубину дерева решений выше и решать отдельную задачу оптимизации для всех возможных глубин в диапазоне, вы берете класс всех деревьев решений и штрафуете каждое дерево пропорционально его глубине (или некоторому монотонно возрастающему функция глубины). Таким образом, количество, которое вы пытаетесь минимизировать, представляет собой линейную комбинацию ошибки обучения и члена штрафа за глубину. Когда вес члена штрафа за глубину достаточно велик, деревья с большой глубиной будут иметь очень большие значения члена штрафа и, следовательно, станут неоптимальными, поэтому вы эффективно ищете пространство T 1 T 1 T_1; когда вес члена штрафа глубины достаточно мал, деревья с большой глубиной не имеют члена большой глубины, но имеют меньшие ошибки, чем деревья меньшего размера, поэтому вы эффективно ищете пространство T k T k T_k.

Таким образом, для оптимального взвешивания члена ошибки и члена глубины исключаются деревья с очень малой глубиной, потому что они имеют большую ошибку обучения, а деревья с большой глубиной исключаются, потому что они имеют большой член глубины. Тогда оптимальное дерево находится где-то посередине.

Этот метод добавления «члена сложности» к ошибочному члену для устранения очень сложных функций называется регуляризацией.

==================================================================================================================================================================
По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?
==================================================================================================================================================================

Обычный способ вычисления значений важности признаков одного дерева заключается в следующем:
1)вы инициализируете массив feature_importances всех нулей размером n_features .
2)вы проходите по дереву: для каждого внутреннего узла, который разбивается на функцию i , вы вычисляете уменьшение ошибки этого узла, умноженное на количество выборок, которые были направлены на узел, и добавляете это количество к feature_importances[i] .

Уменьшение погрешности зависит от используемого критерия примеси (например, Джини, Энтропия, MSE, ...).-это примесь набора примеров, которая направляется во внутренний узел за вычетом суммы примесей двух разделов, созданных в результате разделения.
Важно, чтобы эти значения относились к определенному набору данных (как уменьшение ошибок, так и количество выборок зависят от конкретного набора данных), поэтому эти значения нельзя сравнивать между различными наборами данных.
